---
title: "Rapport de laboratoire 1: modélisation et résolution de problèmes avec IPOPT"
subtitle: "MTH8408"
author:
  - name: Amami Yasmine
    email: yasmine.amami@polymtl.ca
    affiliation:
      - name: Polytechnique Montréal
format:
  pdf:
    keep-tex: false
    documentclass: scrartcl
    geometry:
      - margin=1in
    papersize: letter
    colorlinks: true
    urlcolor: blue
engine: julia
---

```{julia}
#| output: false
using Pkg
Pkg.activate("rapport_env")    # activate a virtual environment
using ADNLPModels
using NLPModelsIpopt
```

# Modélisation d'un problème avec contraintes

Modéliser le problème
$$
\min_{x \in \mathbb{R}^2} \ (x_1 - 2)^2 + (x_2 - 1)^2 \quad \text{s.c.} \ x_1^2 - x_2 \leq 0, \ x_1 + x_2 \leq 2
$$
à l'aide de [`ADNLPModels.jl`](https://github.com/JuliaSmoothOptimizers/ADNLPModels.jl) et le résoudre avec IPOPT à l'aide de [`NLPModelsIpopt.jl`](https://github.com/JuliaSmoothOptimizers/NLPModelsIpopt.jl).
Vous pouvez fournir à IPOPT un point initial de votre choix.
Il ne requiert pas un point initial réalisable (c'est-à-dire qui satisfait les contraintes).

Nous avons vu en classe comment modéliser un problème sans contraintes.
Dirigez-vous vers https://jso.dev/ADNLPModels.jl/stable/ pour découvrir comment modéliser des contraintes.
Effectuez les opérations suivantes :

1. résolvez ce problème avec IPOPT et faites afficher la solution ;

```{julia}
# Insérez votre code ici

f(x) = (x[1] - 2)^2 + (x[2] - 1)^2
g(x) = [x[1]^2 - x[2], x[1] + x[2] - 2]

x0 = [1.0, 1.0]

lcon = [-Inf, -Inf]
ucon = [0.0, 0.0]

lvar = fill(-Inf, 2)
uvar = fill(Inf, 2)

nlp = ADNLPModel(f, x0, lvar, uvar, g, lcon, ucon)

results = ipopt(nlp)

println("Solution :", results.solution)
```

2. donnez le statut final d'IPOPT ;


```{julia}
# Insérez votre code ici
println("Final status: ", results.status)
```

3. Validez manuellement que la solution vérifie les contraintes ;

```{julia}
# Insérez votre code ici
constraints_satisfaction = all(abs.(g(results.solution)) .<= 1e-5)
println("Are the constraints satisfied here :", constraints_satisfaction)
```

4. faites afficher les résidu d'optimalité calculés par IPOPT, contenues dans `stats.primal_feas` et `stats.dual_feas`, respectivement.
   NB: `primal_feas` donne la satisfaction des contraintes et `dual_feas` est la norme du gradient du lagrangien du problème.

```{julia}
# Insérez votre code ici
println("Primal_feas : ", results.primal_feas)
println("Dual_feas : ", results.dual_feas)
```

# Modélisation d'un problème dégénéré

Modéliser le problème
$$
\min_{x \in \mathbb{R}} \ x \quad \text{s.c.} \ x^2 = 0
$$
à l'aide de [`ADNLPModels.jl`](https://github.com/JuliaSmoothOptimizers/ADNLPModels.jl) et le résoudre avec IPOPT à l'aide de [`NLPModelsIpopt.jl`](https://github.com/JuliaSmoothOptimizers/NLPModelsIpopt.jl).

Un solveur comme IPOPT ne requiert pas un point initial réalisable.
Utilisez le point initial $x = 1$.

```{julia}
# Insérez votre code ici
f_degenerate(x) = x[1]
g_degenerate(x) = [x[1]^2]

x0_degenerate  = [1.0]

lvar_d = fill(-Inf, 1)
uvar_d = fill(Inf, 1)

lcon_d = [0.0]
ucon_d = [0.0]

nlp_degenerate = ADNLPModel(f_degenerate, x0_degenerate, lvar_d, uvar_d, g_degenerate, lcon_d, ucon_d)

results_degenerate = ipopt(nlp_degenerate)

println("Solution for degenerate problem :", results_degenerate.solution)
println("Final status of degenerate IPOPT : ", results_degenerate.status)
println("Primal_feas (degenerate): ", results_degenerate.primal_feas)
println("Dual_feas (degenerate): ", results_degenerate.dual_feas)

```

Commentez le statut final d'IPOPT, les résidus d'optimalité, ainsi que la solution finale identifiée.
Ajoutez vos propres commentaires concernant ce problème d'optimisation.

## Commentaires

<!-- Insérez vos commentaires ci-dessous. -->
The constraints may cause issues to resolve the problem
