---
title: "Rapport de laboratoire 1: modélisation et résolution de problèmes avec IPOPT"
subtitle: "MTH8408"
author:
  - name: Dawut Esse
    email: dawut.esse@polymtl.ca
    affiliation:
      - name: Polytechnique Montréal
format:
  pdf:
    keep-tex: false
    documentclass: scrartcl
    geometry:
      - margin=1in
    papersize: letter
    colorlinks: true
    urlcolor: blue
engine: julia
---

```{julia}
#| output: false
using Pkg
Pkg.activate("rapport_env")    # activate a virtual environment
Pkg.add(["JuMP", "Ipopt"]);
```

# Modélisation d'un problème avec contraintes

Modéliser le problème
$$
\min_{x \in \mathbb{R}^2} \ (x_1 - 2)^2 + (x_2 - 1)^2 \quad \text{s.c.} \ x_1^2 - x_2 \leq 0, \ x_1 + x_2 \leq 2
$$
à l'aide de [`ADNLPModels.jl`](https://github.com/JuliaSmoothOptimizers/ADNLPModels.jl) et le résoudre avec IPOPT à l'aide de [`NLPModelsIpopt.jl`](https://github.com/JuliaSmoothOptimizers/NLPModelsIpopt.jl).
Vous pouvez fournir à IPOPT un point initial de votre choix.
Il ne requiert pas un point initial réalisable (c'est-à-dire qui satisfait les contraintes).

Nous avons vu en classe comment modéliser un problème sans contraintes.
Dirigez-vous vers https://jso.dev/ADNLPModels.jl/stable/ pour découvrir comment modéliser des contraintes.
Effectuez les opérations suivantes :

1. résolvez ce problème avec IPOPT et faites afficher la solution ;

```{julia}
# Insérez votre code ici
using JuMP, Ipopt
using LinearAlgebra

m1 = Model(Ipopt.Optimizer)
@variable(m1, x[1:2])
@NLobjective(m1, Min, (x[1] - 2)^2 + (x[2] - 1)^2)
@NLconstraint(m1, x[1]^2 - x[2] <= 0)
@constraint(m1, x[1] + x[2] <= 2)

# Résolution
optimize!(m1)

# 1. Solution trouvée
sol1 = value.(x)
println("Solution x* = ", sol1)
```

2. donnez le statut final d'IPOPT ;

```{julia}
# Insérez votre code ici
println("Statut : ", termination_status(m1))
```

3. Validez manuellement que la solution vérifie les contraintes ;

```{julia}
# Insérez votre code ici
println("C1 = x1^2 - x2 = ", sol1[1]^2 - sol1[2])
println("C2 = x1 + x2 =   ", sol1[1] + sol1[2])
```

4. faites afficher les résidu d'optimalité calculés par IPOPT, contenues dans `stats.primal_feas` et `stats.dual_feas`, respectivement.
   NB: `primal_feas` donne la satisfaction des contraintes et `dual_feas` est la norme du gradient du lagrangien du problème.

```{julia}
# Insérez votre code ici

using JuMP, Ipopt, LinearAlgebra

# 1. Création du modèle et des contraintes
m1 = Model(Ipopt.Optimizer)
@variable(m1, x[1:2])
@NLobjective(m1, Min, (x[1] - 2)^2 + (x[2] - 1)^2)
c1 = @NLconstraint(m1, x[1]^2 - x[2] <= 0)
c2 = @constraint(m1, x[1] + x[2] <= 2)

# 2. Résolution
optimize!(m1)
sol1 = value.(x)

# 3. Affichage de la solution
println("Solution x* = ", sol1)

# 4. Résidus d'optimalité
# --- primal feasibility
viol1 = max(sol1[1]^2 - sol1[2], 0.0)
viol2 = max(sol1[1] + sol1[2] - 2, 0.0)
println("Primal feas (max violation): ", max(viol1, viol2))

# --- dual feasibility
λ1 = dual(c1)
λ2 = dual(c2)
g1 = 2*(sol1[1] - 2) + λ1*2*sol1[1] + λ2
g2 = 2*(sol1[2] - 1) - λ1 + λ2
println("Dual feas (norm grad Lagrangien): ", norm([g1, g2]))

```

# Modélisation d'un problème dégénéré

Modéliser le problème
$$
\min_{x \in \mathbb{R}} \ x \quad \text{s.c.} \ x^2 = 0
$$
à l'aide de [`ADNLPModels.jl`](https://github.com/JuliaSmoothOptimizers/ADNLPModels.jl) et le résoudre avec IPOPT à l'aide de [`NLPModelsIpopt.jl`](https://github.com/JuliaSmoothOptimizers/NLPModelsIpopt.jl).

Un solveur comme IPOPT ne requiert pas un point initial réalisable.
Utilisez le point initial $x = 1$.

```{julia}
# Insérez votre code ici
###############################################################################
# 0.  Packages
using ADNLPModels          # description du problème
using NLPModelsIpopt       # appel d'IPOPT

# 1.  Définition du problème
f(x) = x[1]                # objectif
c(x) = [x[1]^2]            # contrainte  g(x) = 0
x0    = [1.0]              # point initial (non réalisable)

nlp = ADNLPModel(
         f, x0;            # objectif + point initial
         c   = c,          # fonction de contraintes
         lcon = [0.0],     # bornes inférieures
         ucon = [0.0]      # bornes supérieures
       )

# 2.  Appel d’IPOPT
stats = ipopt(nlp; print_level = 5)      # ou print_level = 0 pour silence

# 3.  Résumé rapide
println("\n======= IPOPT =======")
println("Statut    : ", stats.status)
println("Itérations: ", stats.iter)
println("x*        : ", stats.solution)
println("f(x*)     : ", stats.objective)
println("‖g(x*)‖   : ", stats.primal_feas)   # violation contrainte
println("‖∇ₓL‖     : ", stats.dual_feas)     # résidu dual
###############################################################################

```

Commentez le statut final d'IPOPT, les résidus d'optimalité, ainsi que la solution finale identifiée.
Ajoutez vos propres commentaires concernant ce problème d'optimisation.

## Commentaires

<!-- Insérez vos commentaires ci-dessous. -->
Dans le cadre de la modélisation d’un problème dégénéré, le résumé IPOPT affichant status = unknown, iter = –1, un pas gigantesque vers −1.8 × 10²⁰ et un résidu primal nul révèle que la contrainte x^2=0 n’a pas été transmise au modèle : IPOPT s’est donc retrouvé sans aucune restriction, a constaté que l’objectif linéaire f(x)=x est non borné vers −∞ et a quitté aussitôt avec un gradient infini.
