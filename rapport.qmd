---
title: "Rapport de laboratoire 1: modélisation et résolution de problèmes avec IPOPT"
subtitle: "MTH8408"
author:
  - name: Votre nom
    email: votre.adresse@polymtl.ca
    affiliation:
      - name: Polytechnique Montréal
format:
  pdf:
    keep-tex: false
    documentclass: scrartcl
    geometry:
      - margin=1in
    papersize: letter
    colorlinks: true
    urlcolor: blue
# engine: julia  Je l'ai désactié 
---

```{julia}
#| output: false
using Pkg
Pkg.activate("rapport_env")    # activate a virtual environment
```

# Modélisation d'un problème avec contraintes

Modéliser le problème
$$
\min_{x \in \mathbb{R}^2} \ (x_1 - 2)^2 + (x_2 - 1)^2 \quad \text{s.c.} \ x_1^2 - x_2 \leq 0, \ x_1 + x_2 \leq 2
$$
à l'aide de [`ADNLPModels.jl`](https://github.com/JuliaSmoothOptimizers/ADNLPModels.jl) et le résoudre avec IPOPT à l'aide de [`NLPModelsIpopt.jl`](https://github.com/JuliaSmoothOptimizers/NLPModelsIpopt.jl).
Vous pouvez fournir à IPOPT un point initial de votre choix.
Il ne requiert pas un point initial réalisable (c'est-à-dire qui satisfait les contraintes).

Nous avons vu en classe comment modéliser un problème sans contraintes.
Dirigez-vous vers https://jso.dev/ADNLPModels.jl/stable/ pour découvrir comment modéliser des contraintes.
Effectuez les opérations suivantes :

1. résolvez ce problème avec IPOPT et faites afficher la solution ;

```{julia}
# Insérez votre code ici

using Pkg
Pkg.add("ADNLPModels")       # For modeling the optimization problem
Pkg.add("NLPModelsIpopt")    # For solving the problem with IPOPT
Pkg.add("Ipopt")             # Install the IPOPT solver

using ADNLPModels
using NLPModelsIpopt

Include (ADNLPModels.jl)
Include (NLPModelsIpopt.jl)

# La fonction objectif
f(x) = (x[1] - 2)^2 + (x[2] - 1)^2  # centrée sur (2,1)

# Les contraintes
cont1(x) = x[1]^2 - x[2]       # x1^2 - x2 <= 0
cont2(x) = x[1] + x[2] - 2     # x1 + x2 <= 2

# Point initial (guess)
x0 = [1.5, 1.0]  # proche du centre (2,1)

# Création du modèle avec ADNLPModels
nlp = ADNLPModel(f, [cont1, cont2], x0)

```

2. donnez le statut final d'IPOPT ;

```{julia}
# Insérez votre code ici

stats = ipopt(nlp)
print(stats)

```

3. Validez manuellement que la solution vérifie les contraintes ;

```{julia}
# Insérez votre code ici
function f(x1, x2)
    return (x1 - 2)^2 + (x2 - 1)^2
end

# Gradient de la fonction
function gradient_f(x1, x2)
    df_dx1 = 2 * (x1 - 2)
    df_dx2 = 2 * (x2 - 1)
    return (df_dx1, df_dx2)
end
2 * (x1 - 2)=0 → x1 = 2
2 * (x2 - 1)=0 → x2 = 1
# Le point stationaire = (2,1)

# Vérifier les contraintes
cont1(x) = 2^2 - 1=3       # x1^2 - x2 <= 0
cont2(x) = 2 + 1 - 2=1     # x1 + x2 <= 2

```

4. faites afficher les résidu d'optimalité calculés par IPOPT, contenues dans `stats.primal_feas` et `stats.dual_feas`, respectivement.
   NB: `primal_feas` donne la satisfaction des contraintes et `dual_feas` est la norme du gradient du lagrangien du problème.

```{julia}
# Insérez votre code ici
# Le fichier n'execute pas. Je n'ai pas de résultat. 
```

# Modélisation d'un problème dégénéré

Modéliser le problème
$$
\min_{x \in \mathbb{R}} \ x \quad \text{s.c.} \ x^2 = 0
$$
à l'aide de [`ADNLPModels.jl`](https://github.com/JuliaSmoothOptimizers/ADNLPModels.jl) et le résoudre avec IPOPT à l'aide de [`NLPModelsIpopt.jl`](https://github.com/JuliaSmoothOptimizers/NLPModelsIpopt.jl).

Un solveur comme IPOPT ne requiert pas un point initial réalisable.
Utilisez le point initial $x = 1$.

```{julia}
# Insérez votre code ici
# La fonction objectif
f(x) = x

# Les contraintes
c(x) = x^2       # x^2 = 0

# Point initial (guess)
x0 = [1] 

# Création du modèle avec ADNLPModels
nlp = ADNLPModel(f, c, x0)

stats = ipopt(nlp)
print(stats)

```

Commentez le statut final d'IPOPT, les résidus d'optimalité, ainsi que la solution finale identifiée.
Ajoutez vos propres commentaires concernant ce problème d'optimisation.

## Commentaires

<!-- Insérez vos commentaires ci-dessous. -->
Pour la première fonction, j'ai trouvé le point (1,1) en utilisant MATLAB.
Pour la deuxième, j'ai trouvé x = 0.0000010. Il est important de bien définir les chiffres après décimale
Le fichier dans VSCode (Windows) ne fonctionne pas et je ne sais plus quoi faire. 

Références: 
1- https://jso.dev/tutorials/introduction-to-nlpmodelsipopt/
2- https://github.com/JuliaSmoothOptimizers/ADNLPModels.jl
3- https://jso.dev/ADNLPModels.jl/stable/
4- GPT et les resources ouvertes.
